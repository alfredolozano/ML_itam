{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stochastic gradient descend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import norm\n",
    "from sklearn import preprocessing\n",
    "from random import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/ilan/Documents/GitHub/MaterialyTareas/datos/regLinPoli.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.052380</td>\n",
       "      <td>3113.669342</td>\n",
       "      <td>1.542203</td>\n",
       "      <td>-0.011250</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>3113.490528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.379936</td>\n",
       "      <td>2891.956247</td>\n",
       "      <td>0.452374</td>\n",
       "      <td>0.717016</td>\n",
       "      <td>297.191016</td>\n",
       "      <td>2892.963581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006314</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-2.199666</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.174764</td>\n",
       "      <td>537.069692</td>\n",
       "      <td>1.365015</td>\n",
       "      <td>-0.731530</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>522.757565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.655827</td>\n",
       "      <td>2271.077831</td>\n",
       "      <td>1.678116</td>\n",
       "      <td>-0.046938</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>2262.728789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>71.372550</td>\n",
       "      <td>5094.040864</td>\n",
       "      <td>1.853531</td>\n",
       "      <td>0.732296</td>\n",
       "      <td>885.000000</td>\n",
       "      <td>5093.260718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.873062</td>\n",
       "      <td>9974.628611</td>\n",
       "      <td>1.999448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1142.000000</td>\n",
       "      <td>10028.067820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 X           X2           X3           X4           X5  \\\n",
       "count  1029.000000  1029.000000  1029.000000  1029.000000  1029.000000   \n",
       "mean     48.052380  3113.669342     1.542203    -0.011250   628.000000   \n",
       "std      28.379936  2891.956247     0.452374     0.717016   297.191016   \n",
       "min       0.006314     0.000040    -2.199666    -0.999993   114.000000   \n",
       "25%      23.174764   537.069692     1.365015    -0.731530   371.000000   \n",
       "50%      47.655827  2271.077831     1.678116    -0.046938   628.000000   \n",
       "75%      71.372550  5094.040864     1.853531     0.732296   885.000000   \n",
       "max      99.873062  9974.628611     1.999448     1.000000  1142.000000   \n",
       "\n",
       "                  y  \n",
       "count   1029.000000  \n",
       "mean    3113.490528  \n",
       "std     2892.963581  \n",
       "min        0.000040  \n",
       "25%      522.757565  \n",
       "50%     2262.728789  \n",
       "75%     5093.260718  \n",
       "max    10028.067820  "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here df.columns i# Separate both train and test as well as the response variable\n",
    "#X_train=np.array(df[df.columns[0:-1]])[index==1]\n",
    "#X_test=np.array(df[df.columns[0:-1]])[index==0]\n",
    "#Y_train=np.array(df[df.columns[-1]])[index==1]\n",
    "#Y_test=np.array(df[df.columns[-1]])[index==0] \n",
    "# a list of all the columns and df.columns[0:-1] is all columns minus the last which is y. \n",
    "# If the data had headers you could use column names: df[['column1','column2','etc']]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df[df.columns[0:-1]],df[[df.columns[-1]]], train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# index for selecting data 0.75 is the percentage in training\n",
    "index=np.array([1 if random() < 0.75 else 0 for i in range(len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate both train and test as well as the response variable\n",
    "X_train=np.asarray(X_train)\n",
    "X_test=np.asarray(X_test)\n",
    "Y_train=np.asarray(Y_train)\n",
    "Y_test=np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizar no ayuda mucho pero sale igual al de sklearn. Para que las alturas del pdf signifiquen lo mismo \n",
    "#scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "#X_train=scaler.transform(X_train)\n",
    "#X_test=scaler.transform(X_test)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaleX=preprocessing.StandardScaler()\n",
    "scaleY=preprocessing.StandardScaler()\n",
    "\n",
    "scaleX.fit(X_train)\n",
    "X_train=scaleX.transform(X_train)\n",
    "X_test=scaleX.transform(X_test)\n",
    "\n",
    "scaleY.fit(Y_train)\n",
    "Y_train=scaleY.transform(Y_train)\n",
    "Y_test=scaleY.transform(Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.19607092 -0.08257016  0.41246405  0.02386024 -1.55061793]\n"
     ]
    }
   ],
   "source": [
    "numrows=len(X_train)\n",
    "numcols=len(X_train[0])\n",
    "\n",
    "w=np.ones(numcols+1)\n",
    "a=np.array(X_train[0])\n",
    "x=[1]\n",
    "x=np.concatenate((x,a), axis=0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#Iterativo normal\n",
    "w=np.ones(numcols+1)\n",
    "print(w)\n",
    "lam=0.00\n",
    "for j in range(0,9):\n",
    "\n",
    "    for i in range(0, (numrows-1)):\n",
    "        a=np.array(X_train[i])\n",
    "        x=[1]\n",
    "        #print(x)\n",
    "        x=np.concatenate((x,a), axis=0)\n",
    "        #print(x)\n",
    "        v=np.dot(w,x)\n",
    "        #print(v)\n",
    "        #print(f)\n",
    "        aux=w[0]\n",
    "        w=w+.01*((Y_train[i]-v))*x-lam*w\n",
    "        #print(w)\n",
    "        w[0]=w[0]+lam*aux\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00239822  0.3313467   0.76009884 -0.10737539 -0.00919409  0.00381365]\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00221643448303\n"
     ]
    }
   ],
   "source": [
    "numrows=len(X_test)\n",
    "Y_error= []\n",
    "for i in range(0, (numrows)):\n",
    "    a=np.array(X_test[i])\n",
    "    x=[1]\n",
    "    x=np.concatenate((x,a), axis=0)\n",
    "    Y_error.append(np.dot(w,x))\n",
    "\n",
    "    \n",
    "\n",
    "error= mean_squared_error(Y_test, Y_error)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#Minibatch\n",
    "\n",
    "numrows=len(X_train)\n",
    "numcols=len(X_train[0])\n",
    "numBadge=50\n",
    "\n",
    "w=np.ones(numcols+1)\n",
    "print(w)\n",
    "lam=0.001\n",
    "for j in range(0,(numrows)*4):\n",
    "    \n",
    "    randomSample=np.random.choice(numrows-1, numBadge)\n",
    "    vv=[]\n",
    "    xx=np.zeros(numcols+1)\n",
    "    for i in randomSample:\n",
    "        a=np.array(X_train[i])\n",
    "        x=[1]\n",
    "        x=np.concatenate((x,a), axis=0)\n",
    "        vv.append(np.dot(w,x))\n",
    "        xx=xx+x\n",
    "    \n",
    "    #print(v)\n",
    "    #print(f)\n",
    "    x=xx/numBadge\n",
    "    v=np.mean(vv)\n",
    "    aux=w[0]\n",
    "    w=w+.01*((Y_train[i]-v))*x-lam*w\n",
    "    #print(w)\n",
    "    w[0]=w[0]+lam*aux\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07427658  0.10537323  0.11612419  0.07995737  0.02434805 -0.01444749]\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.562942200308\n"
     ]
    }
   ],
   "source": [
    "numrows=len(X_test)\n",
    "Y_error= []\n",
    "for i in range(0, (numrows)):\n",
    "    a=np.array(X_test[i])\n",
    "    x=[1]\n",
    "    x=np.concatenate((x,a), axis=0)\n",
    "    Y_error.append(np.dot(w,x))\n",
    "\n",
    "    \n",
    "\n",
    "error= mean_squared_error(Y_test, Y_error)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
